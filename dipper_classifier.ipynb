{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Import Statements"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "c1 = open('S6_feats-S6-C1-feats_5scut.pkl', 'rb')\n",
    "c2 = open('S6_feats-S6-C2-feats_5scut.pkl', 'rb')\n",
    "c3 = open('S6_feats-S6-C3-feats_5scut.pkl', 'rb')\n",
    "c4 = open('S6_feats-S6-C4-feats_5scut.pkl', 'rb')\n",
    "\n",
    "d1 = pd.read_pickle(c1)\n",
    "d2 = pd.read_pickle(c2)\n",
    "d3 = pd.read_pickle(c3)\n",
    "d4 = pd.read_pickle(c4)\n",
    "\n",
    "data = pd.concat([d1, d2, d3, d4])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clean Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "junk_tics = [91924940, 234661768, 281897530, 153545882, 282051280, 153545868, 91863758, 50589230, 287769916, 31742413,\n",
    "             322895826, 119690108, 322895794, 119689919, 302761551, 281980550, 91922911, 281979571, 287957207, 281980466,\n",
    "             259543633, 31816351, 281980360, 47346711, 397186531, 119555751, 119689376, 119690511, 120381685, 134199361,\n",
    "             142105922, 142105969, 143143921, 146911567, 167303776, 167338401, 167362377, 176980088, 177022355, 219184692,\n",
    "             269205934, 269208586, 269273824, 269274274, 279319817, 280867759, 287957147, 322742255, 322897564, 427394477]\n",
    "\n",
    "var_tics = [387225893, 11295270, 149250423, 381975513, 100479926, 281853128, 370039101, 31473897, 271553990, 238230361,\n",
    "            153096567, 443418729, 138979820, 287532827, 234037006, 119364133, 149349182, 30928630, 271973253, 386320787,\n",
    "            365642947, 200518399, 317091666, 32929951, 442933194, 200515351, 438521908, 332919383, 427349922, 388935228,\n",
    "            50529755, 284283865, 200592903, 11286019, 276664304, 4352884, 50788340, 279578258, 200516548, 4357441,\n",
    "            427348371, 199898021, 200478060, 72921546, 762225404, 457250777, 92017453, 382144165, 40405809, 158733064]\n",
    "\n",
    "eb_tics = [263272042, 251238463, 141213462, 53328873, 67038755, 410901165, 283005536, 147260698, 235457825, 144542315,\n",
    "           151354333, 293776750, 247870021, 220025156, 234879341, 31403133, 143177176, 229306812, 80608317, 281803169,\n",
    "           24623945, 220241814, 52579544, 67192771, 234625764, 100509705, 100682066, 100682887, 102282850, 102405788,\n",
    "           102411949, 102541006, 102571243, 11293508, 11412481, 11693134, 117666617, 117765901, 117883206, 11807985,\n",
    "           11808371, 118929099, 119461300, 119549533, 12036808, 281804470, 282083645, 282263788, 282381271, 284999958]\n",
    "\n",
    "dip_tics = [72828661, 11286045, 388935312, 72833961, 4357786, 11286071, 427395986, 11286063, 427377818, 158822738,\n",
    "            52209961, 436013289, 50530445, 459989537, 279640885, 388935622, 220322494, 206901502, 427377817, 158764834,\n",
    "            436159171, 302672869, 264541453, 309795677, 207045924, 159089190, 34397579, 457231768, 4206238, 349924407,\n",
    "            200639492, 317873721, 436248202, 200591757, 284158141, 302762301, 427400158, 427395634, 365643370, 427380721,\n",
    "            427334205, 200640498, 207017053, 24775707, 11197417, 264739659, 457251847, 457250759, 302830280, 144666684]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "data['label'] = None\n",
    "data.loc[junk_tics, 'label'] = 'JUNK'  # Junk\n",
    "data.loc[var_tics, 'label'] = 'VAR'  # Variable\n",
    "data.loc[eb_tics, 'label'] = 'EB'  # Eclipsing Binary\n",
    "data.loc[dip_tics, 'label'] = 'DIP'  # Dipper"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "data_labeled = data.dropna(subset=['label'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "labels = np.array(data_labeled['label'])\n",
    "data_unlabeled = data_labeled.drop('label', axis = 1)\n",
    "feature_list = list(data_unlabeled.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(data_unlabeled, labels, test_size = 0.5, random_state = 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL ACCURACY:  0.86\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 5, random_state=0)\n",
    "rf.fit(train_features, train_labels)\n",
    "pred_labels = rf.predict(test_features)\n",
    "\n",
    "print(\"MODEL ACCURACY: \", metrics.accuracy_score(test_labels, pred_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get Dipper Candidates"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "data_all = data.drop('label', axis=1)\n",
    "pred = rf.predict(data_all)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIP :\t 41106\n",
      "EB :\t 69172\n",
      "JUNK :\t 2616970\n",
      "VAR :\t 52477\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(pred, return_counts=True)\n",
    "for i in range(0, len(unique)):\n",
    "    print(unique[i], ':\\t', counts[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "data_pred = data_all.copy()\n",
    "data_pred['prediction'] = pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "confidence = rf.predict_proba(data_all)\n",
    "data_pred['dip_confidence'] = confidence[:, 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "           longtermtrend  meanmedrat     skews     varss  coeffvar      stds  \\\n427377818     129.721323    1.345634  0.987055  0.222756 -0.106987  0.776875   \n220322339      13.383646    0.094584  0.973569  0.021303 -0.000062  0.066902   \n237602818       6.281984    0.022612  0.980632  0.007162 -0.000751  0.035932   \n144728975       7.613080    0.047698  0.984597  0.013209 -0.007919  0.050833   \n234089891       4.310072    0.038779  0.982898  0.008161 -0.001788  0.080365   \n...                  ...         ...       ...       ...       ...       ...   \n50792974       15.331776    0.059187  0.974126  0.012304  0.004785  0.050832   \n242066344      37.389562    0.072375  0.806722  0.020132  0.013989  0.170037   \n242065936       5.084903    0.018521  0.910945  0.002855  0.002436  0.015935   \n167970588      19.430053    0.018781  0.463350  0.005079  0.003117  0.041856   \n31178435        2.832225    0.020303  0.967164  0.004052  0.001601  0.005265   \n\n           numoutliers  numnegoutliers  numposoutliers  numout1s  ...  \\\n427377818     0.957712       -0.894645        3.246358      19.0  ...   \n220322339     0.908787       -0.999427        0.621773      16.0  ...   \n237602818     0.854231       -0.984867       -1.182578      26.0  ...   \n144728975     0.850498       -0.891116       -1.121463      16.0  ...   \n234089891     0.959617       -0.962660        0.043017      28.0  ...   \n...                ...             ...             ...       ...  ...   \n50792974      1.089542       -1.049970        1.706593      21.0  ...   \n242066344     0.207746       -1.040636        9.957060      35.0  ...   \n242065936     1.348477       -1.077781       27.373406      28.0  ...   \n167970588     0.893686       -1.016515       -1.071857      40.0  ...   \n31178435      0.285265       -1.090282        7.225536      11.0  ...   \n\n           sautocorrcoef  autocorrcoef  flatmean  tflatmean  roundmean  \\\n427377818      -1.357347      0.794371  0.219082   0.811178  -2.676161   \n220322339      -0.627287      0.944708  0.021220   0.073616  -0.003994   \n237602818       0.029283      1.011927  0.007140   0.042064   0.536771   \n144728975       0.199565      1.000932  0.013173   0.059768  -0.368349   \n234089891       0.221899      1.099819  0.008154   0.083747   0.778314   \n...                  ...           ...       ...        ...        ...   \n50792974       -0.054935      0.995917  0.012271   0.046655  -1.059675   \n242066344       0.323273      1.037074  0.020012   0.818483   1.109531   \n242065936       0.077544      1.050429  0.002854   0.011817  -0.333342   \n167970588       0.041088      1.015127  0.005076   0.046836  -1.114021   \n31178435        0.714327      1.284096  0.004052   0.018456  -0.416566   \n\n           troundmean  roundrat   flatrat  prediction  dip_confidence  \n427377818    1.525118  2.444883  0.047997         DIP             1.0  \n220322339    0.026805  0.038515  0.000450         DIP             1.0  \n237602818    0.001226  0.003651  0.000051         DIP             1.0  \n144728975    0.004567  0.009242  0.000174         DIP             1.0  \n234089891    0.001395  0.003599  0.000066         DIP             1.0  \n...               ...       ...       ...         ...             ...  \n50792974     0.006578  0.016199  0.000151         DIP             0.4  \n242066344    0.136123  0.259437  0.000400         DIP             0.4  \n242065936    0.000702  0.001759  0.000008         DIP             0.4  \n167970588    0.013392  0.049586  0.000026         DIP             0.4  \n31178435     0.000260  0.000603  0.000016         DIP             0.4  \n\n[41106 rows x 62 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>longtermtrend</th>\n      <th>meanmedrat</th>\n      <th>skews</th>\n      <th>varss</th>\n      <th>coeffvar</th>\n      <th>stds</th>\n      <th>numoutliers</th>\n      <th>numnegoutliers</th>\n      <th>numposoutliers</th>\n      <th>numout1s</th>\n      <th>...</th>\n      <th>sautocorrcoef</th>\n      <th>autocorrcoef</th>\n      <th>flatmean</th>\n      <th>tflatmean</th>\n      <th>roundmean</th>\n      <th>troundmean</th>\n      <th>roundrat</th>\n      <th>flatrat</th>\n      <th>prediction</th>\n      <th>dip_confidence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>427377818</th>\n      <td>129.721323</td>\n      <td>1.345634</td>\n      <td>0.987055</td>\n      <td>0.222756</td>\n      <td>-0.106987</td>\n      <td>0.776875</td>\n      <td>0.957712</td>\n      <td>-0.894645</td>\n      <td>3.246358</td>\n      <td>19.0</td>\n      <td>...</td>\n      <td>-1.357347</td>\n      <td>0.794371</td>\n      <td>0.219082</td>\n      <td>0.811178</td>\n      <td>-2.676161</td>\n      <td>1.525118</td>\n      <td>2.444883</td>\n      <td>0.047997</td>\n      <td>DIP</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>220322339</th>\n      <td>13.383646</td>\n      <td>0.094584</td>\n      <td>0.973569</td>\n      <td>0.021303</td>\n      <td>-0.000062</td>\n      <td>0.066902</td>\n      <td>0.908787</td>\n      <td>-0.999427</td>\n      <td>0.621773</td>\n      <td>16.0</td>\n      <td>...</td>\n      <td>-0.627287</td>\n      <td>0.944708</td>\n      <td>0.021220</td>\n      <td>0.073616</td>\n      <td>-0.003994</td>\n      <td>0.026805</td>\n      <td>0.038515</td>\n      <td>0.000450</td>\n      <td>DIP</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>237602818</th>\n      <td>6.281984</td>\n      <td>0.022612</td>\n      <td>0.980632</td>\n      <td>0.007162</td>\n      <td>-0.000751</td>\n      <td>0.035932</td>\n      <td>0.854231</td>\n      <td>-0.984867</td>\n      <td>-1.182578</td>\n      <td>26.0</td>\n      <td>...</td>\n      <td>0.029283</td>\n      <td>1.011927</td>\n      <td>0.007140</td>\n      <td>0.042064</td>\n      <td>0.536771</td>\n      <td>0.001226</td>\n      <td>0.003651</td>\n      <td>0.000051</td>\n      <td>DIP</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>144728975</th>\n      <td>7.613080</td>\n      <td>0.047698</td>\n      <td>0.984597</td>\n      <td>0.013209</td>\n      <td>-0.007919</td>\n      <td>0.050833</td>\n      <td>0.850498</td>\n      <td>-0.891116</td>\n      <td>-1.121463</td>\n      <td>16.0</td>\n      <td>...</td>\n      <td>0.199565</td>\n      <td>1.000932</td>\n      <td>0.013173</td>\n      <td>0.059768</td>\n      <td>-0.368349</td>\n      <td>0.004567</td>\n      <td>0.009242</td>\n      <td>0.000174</td>\n      <td>DIP</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>234089891</th>\n      <td>4.310072</td>\n      <td>0.038779</td>\n      <td>0.982898</td>\n      <td>0.008161</td>\n      <td>-0.001788</td>\n      <td>0.080365</td>\n      <td>0.959617</td>\n      <td>-0.962660</td>\n      <td>0.043017</td>\n      <td>28.0</td>\n      <td>...</td>\n      <td>0.221899</td>\n      <td>1.099819</td>\n      <td>0.008154</td>\n      <td>0.083747</td>\n      <td>0.778314</td>\n      <td>0.001395</td>\n      <td>0.003599</td>\n      <td>0.000066</td>\n      <td>DIP</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>50792974</th>\n      <td>15.331776</td>\n      <td>0.059187</td>\n      <td>0.974126</td>\n      <td>0.012304</td>\n      <td>0.004785</td>\n      <td>0.050832</td>\n      <td>1.089542</td>\n      <td>-1.049970</td>\n      <td>1.706593</td>\n      <td>21.0</td>\n      <td>...</td>\n      <td>-0.054935</td>\n      <td>0.995917</td>\n      <td>0.012271</td>\n      <td>0.046655</td>\n      <td>-1.059675</td>\n      <td>0.006578</td>\n      <td>0.016199</td>\n      <td>0.000151</td>\n      <td>DIP</td>\n      <td>0.4</td>\n    </tr>\n    <tr>\n      <th>242066344</th>\n      <td>37.389562</td>\n      <td>0.072375</td>\n      <td>0.806722</td>\n      <td>0.020132</td>\n      <td>0.013989</td>\n      <td>0.170037</td>\n      <td>0.207746</td>\n      <td>-1.040636</td>\n      <td>9.957060</td>\n      <td>35.0</td>\n      <td>...</td>\n      <td>0.323273</td>\n      <td>1.037074</td>\n      <td>0.020012</td>\n      <td>0.818483</td>\n      <td>1.109531</td>\n      <td>0.136123</td>\n      <td>0.259437</td>\n      <td>0.000400</td>\n      <td>DIP</td>\n      <td>0.4</td>\n    </tr>\n    <tr>\n      <th>242065936</th>\n      <td>5.084903</td>\n      <td>0.018521</td>\n      <td>0.910945</td>\n      <td>0.002855</td>\n      <td>0.002436</td>\n      <td>0.015935</td>\n      <td>1.348477</td>\n      <td>-1.077781</td>\n      <td>27.373406</td>\n      <td>28.0</td>\n      <td>...</td>\n      <td>0.077544</td>\n      <td>1.050429</td>\n      <td>0.002854</td>\n      <td>0.011817</td>\n      <td>-0.333342</td>\n      <td>0.000702</td>\n      <td>0.001759</td>\n      <td>0.000008</td>\n      <td>DIP</td>\n      <td>0.4</td>\n    </tr>\n    <tr>\n      <th>167970588</th>\n      <td>19.430053</td>\n      <td>0.018781</td>\n      <td>0.463350</td>\n      <td>0.005079</td>\n      <td>0.003117</td>\n      <td>0.041856</td>\n      <td>0.893686</td>\n      <td>-1.016515</td>\n      <td>-1.071857</td>\n      <td>40.0</td>\n      <td>...</td>\n      <td>0.041088</td>\n      <td>1.015127</td>\n      <td>0.005076</td>\n      <td>0.046836</td>\n      <td>-1.114021</td>\n      <td>0.013392</td>\n      <td>0.049586</td>\n      <td>0.000026</td>\n      <td>DIP</td>\n      <td>0.4</td>\n    </tr>\n    <tr>\n      <th>31178435</th>\n      <td>2.832225</td>\n      <td>0.020303</td>\n      <td>0.967164</td>\n      <td>0.004052</td>\n      <td>0.001601</td>\n      <td>0.005265</td>\n      <td>0.285265</td>\n      <td>-1.090282</td>\n      <td>7.225536</td>\n      <td>11.0</td>\n      <td>...</td>\n      <td>0.714327</td>\n      <td>1.284096</td>\n      <td>0.004052</td>\n      <td>0.018456</td>\n      <td>-0.416566</td>\n      <td>0.000260</td>\n      <td>0.000603</td>\n      <td>0.000016</td>\n      <td>DIP</td>\n      <td>0.4</td>\n    </tr>\n  </tbody>\n</table>\n<p>41106 rows Ã— 62 columns</p>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dip = data_pred[data_pred['prediction'] == 'DIP']\n",
    "data_dip = data_dip.sort_values('dip_confidence', ascending=False)\n",
    "data_dip"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "data_dip.to_csv('rf_dip_candidates.csv', columns=['dip_confidence'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}